{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* Evaluer erreurs\n",
    "* Voir les associations mots->classe\n",
    "* Voir les ech. qui activent certaines classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import classif\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train, val, test: 3172 317 1799\n",
      "Bin count train:  [811 143 425  48 783  71  22  99 191 579]\n",
      "Bin count val:    [70 17 43  4 82 13  4 11 14 59]\n",
      "Bin count test:   [467  98 215  21 491  43  14  39  93 318]\n"
     ]
    }
   ],
   "source": [
    "def build_model(num_classes, l2_reg):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(64,), gamma_regularizer=l2(l2_reg)))\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(BatchNormalization(gamma_regularizer=l2(l2_reg)))\n",
    "    model.add(Dense(1024, activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(BatchNormalization(gamma_regularizer=l2(l2_reg)))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=l2(l2_reg)))\n",
    "    \n",
    "    model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train(model: Sequential, data, gen=None, verbose=1, epochs=10):\n",
    "    print('Training...')\n",
    "    if gen:\n",
    "        history = model.fit_generator(gen(), 100, epochs=epochs, verbose=verbose,\n",
    "                                      validation_data=(data['X_val'], data['y_val']))\n",
    "    else:\n",
    "        history = model.fit(data['X_train'], data['y_train'],\n",
    "                            validation_data=(data['X_val'], data['y_val']),\n",
    "                            verbose=verbose)\n",
    "    \n",
    "    return np.max(history.history['val_acc'])\n",
    "    \n",
    "\n",
    "def test(model: Sequential, data):\n",
    "    print('Testing...')\n",
    "    results = model.evaluate(data['X_test'], data['y_test'])\n",
    "    print('\\nLoss: {}  Acc: {}'.format(*results))\n",
    "\n",
    "    \n",
    "data, num_classes, gen = classif.load_data()\n",
    "q_labels = ['Démocratie: Comment reprendre le pouvoir?',\n",
    "'Économie: Comment développer le Québec selon nos priorités?',\n",
    "'Régions: Comment dynamiser toutes nos communautés?',\n",
    "'Indépendance: Comment se remettre en marche?',\n",
    "'Éducation: Comment permettre à tout le monde de réaliser son plein potentiel?',\n",
    "'Premiers Peuples: Comment construire la solidarité entre nous?',\n",
    "'Diversité: Comment vivre ensemble sans racisme ni discrimination?',\n",
    "'Culture: Comment favoriser une création artistique vivante et en assurer l’accès à tous?',\n",
    "'Santé: Comment prendre soin de tout le monde?',\n",
    "'Climat: Comment enclencher la transition?',\n",
    "'On a oublié quelque chose?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying reg=1e-06\n",
      "Training...\n",
      "Using gen\n",
      "Val acc: 0.848580443709\n",
      "Trying reg=1e-05\n",
      "Training...\n",
      "Using gen\n",
      "Val acc: 0.82965299929\n",
      "Trying reg=0.0001\n",
      "Training...\n",
      "Using gen\n",
      "Val acc: 0.813880126935\n",
      "Trying reg=0.001\n",
      "Training...\n",
      "Using gen\n",
      "Val acc: 0.804416402845\n",
      "Trying reg=0.01\n",
      "Training...\n",
      "Using gen\n",
      "Val acc: 0.574132493618\n",
      "Trying reg=0.1\n",
      "Training...\n",
      "Using gen\n",
      "Val acc: 0.359621450258\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "# best l2_reg = 0.01\n",
    "reg_list = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "results = {}\n",
    "\n",
    "for reg in reg_list:\n",
    "    print('Trying reg=' + str(reg))\n",
    "    model = build_model(num_classes, reg)\n",
    "    val_acc = train(model, data, gen, verbose=0, epochs=40)\n",
    "    print('Val acc: ' + str(val_acc))\n",
    "    results[reg] = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Using gen\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 5s - loss: 2.0771 - acc: 0.3756 - val_loss: 2.0835 - val_acc: 0.2776\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 0s - loss: 1.6118 - acc: 0.4862 - val_loss: 1.7261 - val_acc: 0.4227\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 0s - loss: 1.4703 - acc: 0.5328 - val_loss: 1.5102 - val_acc: 0.4606\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 0s - loss: 1.3213 - acc: 0.5863 - val_loss: 1.5593 - val_acc: 0.4826\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 1s - loss: 1.1865 - acc: 0.6206 - val_loss: 1.4209 - val_acc: 0.5584\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 1s - loss: 1.1475 - acc: 0.6272 - val_loss: 1.3285 - val_acc: 0.5457\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 1s - loss: 1.1090 - acc: 0.6512 - val_loss: 1.6228 - val_acc: 0.5142\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 1s - loss: 1.0672 - acc: 0.6584 - val_loss: 1.3086 - val_acc: 0.5678\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 1s - loss: 0.9351 - acc: 0.6959 - val_loss: 1.0548 - val_acc: 0.6625\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 1s - loss: 0.9346 - acc: 0.6934 - val_loss: 1.2510 - val_acc: 0.5962\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 1s - loss: 0.8657 - acc: 0.7172 - val_loss: 1.0351 - val_acc: 0.6593\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 1s - loss: 0.8307 - acc: 0.7347 - val_loss: 1.1835 - val_acc: 0.6057\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 1s - loss: 0.8573 - acc: 0.7253 - val_loss: 0.9496 - val_acc: 0.6593\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 1s - loss: 0.7997 - acc: 0.7216 - val_loss: 0.9043 - val_acc: 0.6909\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 1s - loss: 0.7923 - acc: 0.7391 - val_loss: 1.1186 - val_acc: 0.6530\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 1s - loss: 0.7636 - acc: 0.7472 - val_loss: 0.9568 - val_acc: 0.6467\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 1s - loss: 0.7372 - acc: 0.7566 - val_loss: 0.9228 - val_acc: 0.6751\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 1s - loss: 0.7262 - acc: 0.7556 - val_loss: 0.7472 - val_acc: 0.7508\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 1s - loss: 0.6795 - acc: 0.7753 - val_loss: 0.8886 - val_acc: 0.7098\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 1s - loss: 0.7027 - acc: 0.7700 - val_loss: 0.8576 - val_acc: 0.7287\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 1s - loss: 0.6420 - acc: 0.7931 - val_loss: 0.9063 - val_acc: 0.7066\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 1s - loss: 0.6238 - acc: 0.7934 - val_loss: 0.7867 - val_acc: 0.7129\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 1s - loss: 0.6558 - acc: 0.7847 - val_loss: 0.7271 - val_acc: 0.7445\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 1s - loss: 0.6368 - acc: 0.7922 - val_loss: 0.7377 - val_acc: 0.7634\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 1s - loss: 0.6157 - acc: 0.7953 - val_loss: 0.7249 - val_acc: 0.7855\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 1s - loss: 0.6063 - acc: 0.8044 - val_loss: 0.6486 - val_acc: 0.7729\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 1s - loss: 0.5621 - acc: 0.8122 - val_loss: 0.7795 - val_acc: 0.7508\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 1s - loss: 0.5529 - acc: 0.8287 - val_loss: 0.8135 - val_acc: 0.7445\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 1s - loss: 0.5825 - acc: 0.8044 - val_loss: 0.6688 - val_acc: 0.7981\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 1s - loss: 0.5721 - acc: 0.8162 - val_loss: 0.6653 - val_acc: 0.8013\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 1s - loss: 0.5786 - acc: 0.8128 - val_loss: 0.5752 - val_acc: 0.7886\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 1s - loss: 0.5291 - acc: 0.8228 - val_loss: 0.6945 - val_acc: 0.7666\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 1s - loss: 0.5081 - acc: 0.8363 - val_loss: 0.6475 - val_acc: 0.7950\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 1s - loss: 0.5356 - acc: 0.8259 - val_loss: 0.7090 - val_acc: 0.8076\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 1s - loss: 0.4961 - acc: 0.8359 - val_loss: 0.6355 - val_acc: 0.7886\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 1s - loss: 0.5004 - acc: 0.8337 - val_loss: 0.6715 - val_acc: 0.7886\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 1s - loss: 0.5230 - acc: 0.8322 - val_loss: 0.6543 - val_acc: 0.7760\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 1s - loss: 0.4982 - acc: 0.8381 - val_loss: 0.5612 - val_acc: 0.8013\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 1s - loss: 0.4745 - acc: 0.8469 - val_loss: 0.6637 - val_acc: 0.7792\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 1s - loss: 0.5107 - acc: 0.8359 - val_loss: 0.5845 - val_acc: 0.8170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81703470275981194"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train best model\n",
    "model = build_model(num_classes, 1e-6)\n",
    "train(model, data, gen, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.961423012785\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.78      0.83       451\n",
      "          1       0.84      0.93      0.88        84\n",
      "          2       0.72      0.77      0.75       242\n",
      "          3       0.74      0.94      0.83        34\n",
      "          4       0.79      0.72      0.75       450\n",
      "          5       0.84      0.95      0.89        38\n",
      "          6       0.59      1.00      0.74        13\n",
      "          7       0.84      0.98      0.90        57\n",
      "          8       0.72      0.88      0.79        96\n",
      "          9       0.82      0.88      0.85       334\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(data['X_test'])\n",
    "y_pred = to_categorical(np.argmax(y_pred, axis=1), num_classes)\n",
    "test_acc = np.mean(y_pred == data['y_test'])\n",
    "print('Test accuracy: ' + str(test_acc))\n",
    "print(classification_report(data['y_test'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding answers...\n"
     ]
    }
   ],
   "source": [
    "import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "embedder = word2vec.Embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCvT/aUoT7vNnxDEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a920f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Culture: Comment favoriser une création artistique vivante et en assurer l’accès à tous?\n"
     ]
    }
   ],
   "source": [
    "test_ans = embedder.embed_phrase('Soutenir les poètes, philosophes et écrivains')\n",
    "y_pred = model.predict(test_ans[None, :])\n",
    "plt.figure()\n",
    "plt.stem(y_pred.ravel(), 'o')\n",
    "plt.show()\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(q_labels[int(y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
